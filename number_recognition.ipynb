{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw2US0p1ncbH"
      },
      "source": [
        "# HAND WRITTEN NUMBER RECPGNISION - TENSERFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "svbd_oMDnmRx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sy5g_XIbo9PD"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_class = 10\n",
        "num_features = 28 * 28\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "training_steps = 6000\n",
        "display_step = 100\n",
        "n_hidden1 = 128\n",
        "n_hidden2 = 256\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "glgSrJGeBO7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Flatten and normalize the data\n",
        "x_train = np.array(x_train, dtype=np.float32).reshape([-1, num_features]) / 255.0\n",
        "x_test = np.array(x_test, dtype=np.float32).reshape([-1, num_features]) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1XcBS0eBO4X"
      },
      "outputs": [],
      "source": [
        "# Create training and test datasets\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data = test_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl7IuNNj4gJ-"
      },
      "source": [
        "# FORWARD PROPAGATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oflWClAipsCg"
      },
      "outputs": [],
      "source": [
        "# Initialize weights and biases\n",
        "random_normal = tf.initializers.RandomNormal()\n",
        "\n",
        "weights = {\n",
        "    \"h1\": tf.Variable(random_normal([num_features, n_hidden1])),\n",
        "    \"h2\": tf.Variable(random_normal([n_hidden1, n_hidden2])),\n",
        "    \"output\": tf.Variable(random_normal([n_hidden2, num_class]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    \"b1\": tf.Variable(random_normal([n_hidden1])),\n",
        "    \"b2\": tf.Variable(random_normal([n_hidden2])),\n",
        "    \"output\": tf.Variable(random_normal([num_class]))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8pbRqcysu_ZN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the model\n",
        "def neural_net(x):\n",
        "    layer1 = tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])\n",
        "    layer1 = tf.nn.sigmoid(layer1)\n",
        "    layer2 = tf.add(tf.matmul(layer1, weights[\"h2\"]), biases[\"b2\"])\n",
        "    layer2 = tf.nn.sigmoid(layer2)\n",
        "    output_layer = tf.add(tf.matmul(layer2, weights[\"output\"]), biases[\"output\"])\n",
        "    return tf.nn.softmax(output_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyo1lZbj4tKD"
      },
      "source": [
        "# BACKWARD PROPAGATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1VWtB9qB1bX"
      },
      "outputs": [],
      "source": [
        "# Define loss and accuracy functions\n",
        "def cross_entropy(y_act, y_pred):\n",
        "    y_act = tf.one_hot(y_act, depth=num_class)\n",
        "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_act, y_pred))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsBu78jVvUXI"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "def run_optimisers(x, y):\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = neural_net(x)\n",
        "        loss = cross_entropy(y, pred)\n",
        "    trainable_variables = list(weights.values()) + list(biases.values())\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UywApLw3zU",
        "outputId": "5e381840-fbc3-46ca-a4b1-1dc57d6f3b5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 100, Loss: 2.3162, Accuracy: 0.1055\n",
            "Step: 200, Loss: 2.3058, Accuracy: 0.0742\n",
            "Step: 300, Loss: 2.3029, Accuracy: 0.0664\n",
            "Step: 400, Loss: 2.2971, Accuracy: 0.1133\n",
            "Step: 500, Loss: 2.3012, Accuracy: 0.1094\n",
            "Step: 600, Loss: 2.2980, Accuracy: 0.1133\n",
            "Step: 700, Loss: 2.2977, Accuracy: 0.1172\n",
            "Step: 800, Loss: 2.2986, Accuracy: 0.1211\n",
            "Step: 900, Loss: 2.3055, Accuracy: 0.0898\n",
            "Step: 1000, Loss: 2.2943, Accuracy: 0.1367\n",
            "Step: 1100, Loss: 2.3008, Accuracy: 0.1094\n",
            "Step: 1200, Loss: 2.2986, Accuracy: 0.1016\n",
            "Step: 1300, Loss: 2.2945, Accuracy: 0.1406\n",
            "Step: 1400, Loss: 2.2999, Accuracy: 0.1016\n",
            "Step: 1500, Loss: 2.3002, Accuracy: 0.0898\n",
            "Step: 1600, Loss: 2.2930, Accuracy: 0.1289\n",
            "Step: 1700, Loss: 2.2954, Accuracy: 0.1055\n",
            "Step: 1800, Loss: 2.2913, Accuracy: 0.1367\n",
            "Step: 1900, Loss: 2.2928, Accuracy: 0.1367\n",
            "Step: 2000, Loss: 2.2930, Accuracy: 0.1406\n",
            "Step: 2100, Loss: 2.2943, Accuracy: 0.1094\n",
            "Step: 2200, Loss: 2.2937, Accuracy: 0.1289\n",
            "Step: 2300, Loss: 2.2978, Accuracy: 0.1055\n",
            "Step: 2400, Loss: 2.2929, Accuracy: 0.1289\n",
            "Step: 2500, Loss: 2.2920, Accuracy: 0.1367\n",
            "Step: 2600, Loss: 2.2965, Accuracy: 0.1250\n",
            "Step: 2700, Loss: 2.2956, Accuracy: 0.1016\n",
            "Step: 2800, Loss: 2.2978, Accuracy: 0.0859\n",
            "Step: 2900, Loss: 2.2943, Accuracy: 0.0898\n",
            "Step: 3000, Loss: 2.2986, Accuracy: 0.1094\n",
            "Step: 3100, Loss: 2.2980, Accuracy: 0.1055\n",
            "Step: 3200, Loss: 2.2995, Accuracy: 0.0703\n",
            "Step: 3300, Loss: 2.2956, Accuracy: 0.1133\n",
            "Step: 3400, Loss: 2.2933, Accuracy: 0.1133\n",
            "Step: 3500, Loss: 2.2902, Accuracy: 0.1133\n",
            "Step: 3600, Loss: 2.2997, Accuracy: 0.0781\n",
            "Step: 3700, Loss: 2.2918, Accuracy: 0.1094\n",
            "Step: 3800, Loss: 2.2979, Accuracy: 0.0977\n",
            "Step: 3900, Loss: 2.2937, Accuracy: 0.0938\n",
            "Step: 4000, Loss: 2.2925, Accuracy: 0.1133\n",
            "Step: 4100, Loss: 2.2933, Accuracy: 0.1133\n",
            "Step: 4200, Loss: 2.2880, Accuracy: 0.1250\n",
            "Step: 4300, Loss: 2.2907, Accuracy: 0.1172\n",
            "Step: 4400, Loss: 2.2920, Accuracy: 0.1094\n",
            "Step: 4500, Loss: 2.2887, Accuracy: 0.1094\n",
            "Step: 4600, Loss: 2.2940, Accuracy: 0.0977\n",
            "Step: 4700, Loss: 2.2871, Accuracy: 0.1406\n",
            "Step: 4800, Loss: 2.2925, Accuracy: 0.0859\n",
            "Step: 4900, Loss: 2.2884, Accuracy: 0.0938\n",
            "Step: 5000, Loss: 2.2918, Accuracy: 0.1172\n",
            "Step: 5100, Loss: 2.2878, Accuracy: 0.1406\n",
            "Step: 5200, Loss: 2.2873, Accuracy: 0.1094\n",
            "Step: 5300, Loss: 2.2901, Accuracy: 0.1094\n",
            "Step: 5400, Loss: 2.2874, Accuracy: 0.1055\n",
            "Step: 5500, Loss: 2.2880, Accuracy: 0.1289\n",
            "Step: 5600, Loss: 2.2844, Accuracy: 0.1250\n",
            "Step: 5700, Loss: 2.2855, Accuracy: 0.1445\n",
            "Step: 5800, Loss: 2.2930, Accuracy: 0.0977\n",
            "Step: 5900, Loss: 2.2840, Accuracy: 0.1094\n",
            "Step: 6000, Loss: 2.2855, Accuracy: 0.1328\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training loop\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "    run_optimisers(batch_x, batch_y)\n",
        "\n",
        "    if step % display_step == 0:\n",
        "        pred = neural_net(batch_x)\n",
        "        loss = cross_entropy(batch_y, pred)\n",
        "        acc = accuracy(pred, batch_y)\n",
        "        print(f\"Step: {step}, Loss: {loss.numpy():.4f}, Accuracy: {acc.numpy():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNts1JI25LXx",
        "outputId": "40aafe09-0913-47bf-b6b1-a9b75cd1d83b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Accuracy: 0.1135\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test data\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for batch_x, batch_y in test_data:\n",
        "    pred = neural_net(batch_x)\n",
        "    all_preds.append(pred)\n",
        "    all_labels.append(batch_y)\n",
        "\n",
        "y_pred = tf.concat(all_preds, axis=0)\n",
        "y_true = tf.concat(all_labels, axis=0)\n",
        "\n",
        "test_acc = accuracy(y_pred, y_true)\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc.numpy():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "oq9cNdbmE0Vg",
        "outputId": "96f78617-cda5-4904-994a-ed63d7f2f890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.prediction 1\n",
            "model.prediction 1\n",
            "model.prediction 1\n",
            "model.prediction 1\n",
            "model.prediction 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n_image = 5\n",
        "test_image = x_test[:n_image]\n",
        "prediction=neural_net(test_image)\n",
        "for i in range(n_image):\n",
        "  plt.imshow(np.reshape(test_image[i],[28,28]))\n",
        "  plt.show\n",
        "  print(f\"model.prediction {np.argmax(prediction.numpy()[i])}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
